import json
import torch
from src.config import DEVICE, STATUS_MAP
from src.gating_engine import MoEGateKeeper
from src.experts import get_expert_handler

# æ¨¡æ“¬å‰ç«¯å‚³ä¾†çš„ JSON è³‡æ–™ (æ¸¬è©¦æ¡ˆä¾‹)
TEST_CASES = [
    # Case 1: ç¶ è‰²é€šé“ (VIP é†«å¸«ï¼Œè³‡æ–™å®Œæ•´) -> é æœŸï¼šFRE (Risk Engine)
    {
        "user_query": "æˆ‘æƒ³è¦ç”³è«‹è²¸æ¬¾ï¼Œè³‡æ–™éƒ½å¡«å¥½äº†ï¼Œè«‹ç›¡å¿«æ’¥æ¬¾ã€‚",
        "profile_state": {
            "id": "A123456789", "name": "æŸ¯æ–‡å“²", "job": "å°å¤§é†«å¸«", 
            "income": "300000", "amount": "2000000", "risk_score": 0.0
        },
        "verification_status": "pending"
    },
    # Case 2: æŠ€è¡“æ””æˆª (ä½¿ç”¨è€…æŠ±æ€¨ä¸Šå‚³å¤±æ•—) -> é æœŸï¼šDVE (Tech Support)
    {
        "user_query": "ç‚ºä»€éº¼è²¡åŠ›è­‰æ˜ä¸€ç›´å‚³ä¸ä¸Šå»ï¼Ÿç³»çµ±æ˜¯ä¸æ˜¯å£äº†ï¼Ÿ",
        "profile_state": {
            "id": "B123456789", "name": "ç‹å°æ˜", "job": "å·¥ç¨‹å¸«",
            "income": "50000", "amount": "500000"
        },
        "verification_status": "pending"
    },
    # Case 3: LDE å¼•å° (ç¼ºä»¶ä¸”åœ¨å•å•é¡Œ) -> é æœŸï¼šLDE (Consultant)
    {
        "user_query": "è«‹å•ä½ å€‘çš„åˆ©ç‡å¤§æ¦‚å¤šå°‘ï¼Ÿæˆ‘ä¹Ÿé‚„æ²’å¡«èº«åˆ†è­‰ã€‚",
        "profile_state": {
            "job": "æœå‹™æ¥­", "amount": "100000" 
        },
        "verification_status": "unknown"
    },
    # Case 4: LDE è£œä»¶ (è¢« LDE ç™¼ç¾ç¼ºä»¶) -> é æœŸï¼šLDE (Guide)
    {
        "user_query": "æˆ‘å«æå¤§åŒï¼Œæƒ³å€Ÿåè¬ã€‚",
        "profile_state": {
            "name": "æå¤§åŒ", "amount": "100000"
        },
        "verification_status": "pending"
    }
]

def main():
    print(f"ğŸš€ å•Ÿå‹• MoE è²¸æ¬¾é¢¨éšªæ™ºæ…§åˆ†æµç³»çµ± (Device: {DEVICE})")
    
    # 1. åˆå§‹åŒ–é–€æ§æ¨¡å‹ (Gating Network)
    # è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡ï¼Œæº–å‚™é€²è¡Œè·¯ç”±
    gate_keeper = MoEGateKeeper()
    
    print("\n" + "="*50)
    print("ğŸ§ª é–‹å§‹åŸ·è¡Œæ¸¬è©¦æ¡ˆä¾‹ (Simulating API Requests)")
    print("="*50 + "\n")

    for i, request_data in enumerate(TEST_CASES):
        print(f"ğŸ”¹ [Case {i+1}] User Query: {request_data['user_query']}")
        
        # 2. é–€æ§æ±ºç­– (Routing)
        # è¼¸å…¥ï¼šUser Query + Profile State
        # è¼¸å‡ºï¼šå°ˆå®¶æ¨™ç±¤ (LDE/DVE/FRE), ä¿¡å¿ƒåº¦, æ±ºç­–ç†ç”±
        expert_label, confidence, reason = gate_keeper.predict(request_data)
        
        print(f"   â””â”€â”€ ğŸ¤– Gating Decision: \033[92m{expert_label}\033[0m (Conf: {confidence:.2f})")
        print(f"   â””â”€â”€ ğŸ“ Reason: {reason}")
        
        # 3. å°ˆå®¶èª¿åº¦ (Dispatching)
        # æ ¹æ“šæ¨™ç±¤å¯¦ä¾‹åŒ–å°æ‡‰çš„ Expert Class
        expert = get_expert_handler(expert_label.split()[0]) # å–å‰ç¶´ LDE/DVE/FRE
        
        if expert:
            # 4. å°ˆå®¶åŸ·è¡Œ (Execution)
            # Expert å…§éƒ¨æœƒå‘¼å« Local LLM æˆ– OpenAI
            print(f"   â””â”€â”€ âš™ï¸  Calling {expert_label}...")
            result = expert.process(request_data)
            
            # 5. è¼¸å‡ºçµæœ
            print(f"   â””â”€â”€ ğŸ’¬ Response: {result['response']}")
            print(f"   â””â”€â”€ â­ï¸  Next Step: {result['next_step']}")
            
            # è‹¥æœ‰è³‡æ–™æ›´æ–° (å¦‚ LDE èƒå–äº†æ–°æ¬„ä½)ï¼Œé€™è£¡æ¨¡æ“¬å¯«å›è³‡æ–™åº«
            if "updated_profile" in result:
                print(f"   â””â”€â”€ ğŸ’¾ Database Update: {result['updated_profile']}")
        else:
            print(f"   â””â”€â”€ âŒ Error: No handler found for {expert_label}")
            
        print("-" * 50)

if __name__ == "__main__":
    main()