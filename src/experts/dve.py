import json
import torch
from datetime import datetime
from transformers import TextStreamer
from peft import PeftModel
import re

from ..rag_service import rag_engine
from ..config import DVE_ADAPTER_PATH, DVE_PROMPT_TEMPLATE, DVE_INSTRUCTION, DEVICE
from .base import BaseExpert

class DVE_Expert(BaseExpert):
    """
    DVE: è³‡æ–™æŸ¥æ ¸å°ˆå®¶ (Ultimate Robust Version)
    ç‰¹è‰²: 
    1. Regex JSON æå– (é˜²æ­¢å­—ä¸²å…§æ‹¬è™Ÿå¹²æ“¾)
    2. è‡ªå‹•æ¸…æ´— Hallucination
    3. å‹•æ…‹å­˜æª” (ä¿®å¾©å¯«æ­»æ¬„ä½çš„ Bug)
    """
    def process(self, task_data, history=[]):
        query = task_data.get("user_query", "")
        profile = task_data.get("profile_state", {})
        
        # 1. æŠ€è¡“éšœç¤™æ””æˆª (Rule-based)
        tech_keywords = ["å‚³ä¸ä¸Š", "å¤±æ•—", "æ ¼å¼éŒ¯èª¤", "å¤ªæ…¢", "ç•¶æ©Ÿ", "ç„¡æ³•"]
        if any(k in query for k in tech_keywords):
            return {
                "expert": "DVE (Tech Support)",
                "response": "åµæ¸¬åˆ°æŠ€è¡“å•é¡Œã€‚è«‹ç¢ºèªåœ–ç‰‡æ ¼å¼ç‚º JPG/PNG ä¸”å°æ–¼ 5MBã€‚",
                "next_step": "ç­‰å¾…æŠ€è¡“æ’é™¤"
            }

        print("ğŸ›¡ï¸ DVE å•Ÿå‹• AI æŸ¥æ ¸æ¨¡å¼ (Loading from Metadata)...")

        # --- 2. æº–å‚™ RAG è³‡æ–™ (Context) ---
        user_id = profile.get("id", "UNKNOWN")
        user_name = profile.get("name", "Guest")
        
        # å¾ MongoDB æ’ˆå–
        history_records = rag_engine.get_user_history_by_id(user_id)
        
        rag_context = {}
        
        if history_records:
            print(f"ğŸ” ç™¼ç¾æ­·å²ç´€éŒ„ï¼Œæ­£åœ¨çµ„è£ Context...")
            latest_record = history_records[-1] # å–æœ€æ–°
            meta = latest_record.get("metadata", {})
            
            # ç›´æ¥å¾ Metadata å°æ‡‰åˆ° DVE éœ€è¦çš„ Key
            rag_context = {
                "æª”æ¡ˆä¸­ç´€éŒ„è·æ¥­": meta.get("hist_job", "ç„¡ç´€éŒ„"),
                "ä¸Šæ¬¡è²¸æ¬¾è³‡é‡‘ç”¨é€”": meta.get("hist_purpose", "ç„¡ç´€éŒ„"),
                "æª”æ¡ˆä¸­è¯çµ¡é›»è©±": meta.get("hist_phone", "ç„¡ç´€éŒ„"),
                "æ­·å²é•ç´„ç´€éŒ„": meta.get("default_record", "ç„¡"),
                "æª”æ¡ˆä¸­æœå‹™å…¬å¸åç¨±": meta.get("hist_company", "ç„¡ç´€éŒ„"),
                "æª”æ¡ˆä¸­å¹´è–ª/æœˆè–ª": str(meta.get("hist_income", "0")),
                "ä¿¡ç”¨å ±å‘ŠæŸ¥è©¢æ¬¡æ•¸": str(meta.get("inquiry_count", "0")),
                "åœ°å€è®Šå‹•æ¬¡æ•¸": str(meta.get("addr_change_count", "0"))
            }
        else:
            print("âš ï¸ æ–°ç”¨æˆ¶ (ç„¡æ­·å²ç´€éŒ„)")
            rag_context = {
                "æª”æ¡ˆä¸­ç´€éŒ„è·æ¥­": "ç„¡ç´€éŒ„ (æ–°æˆ¶)",
                "ä¸Šæ¬¡è²¸æ¬¾è³‡é‡‘ç”¨é€”": "ç„¡ç´€éŒ„",
                "æª”æ¡ˆä¸­è¯çµ¡é›»è©±": "ç„¡ç´€éŒ„",
                "æ­·å²é•ç´„ç´€éŒ„": "ç„¡",
                "æª”æ¡ˆä¸­æœå‹™å…¬å¸åç¨±": "ç„¡ç´€éŒ„",
                "æª”æ¡ˆä¸­å¹´è–ª/æœˆè–ª": "0",
                "ä¿¡ç”¨å ±å‘ŠæŸ¥è©¢æ¬¡æ•¸": "0",
                "åœ°å€è®Šå‹•æ¬¡æ•¸": "0"
            }

        # --- 3. çµ„å»º Input JSON ---
        # ç‚ºäº†å­˜æª”æ™‚èƒ½æ‹¿åˆ°æ­£ç¢ºè³‡æ–™ï¼Œæˆ‘å€‘å…ˆæŠŠè®Šæ•¸æå–å‡ºä¾†
        q_job = profile.get("job", "å¾…æ¥­ä¸­")
        q_purpose = profile.get("purpose", "ä¸€èˆ¬é€±è½‰") # å˜—è©¦å¾ profile æŠ“ï¼Œæ²’æœ‰å‰‡é è¨­
        q_phone = profile.get("phone", "09xx-xxx-xxx") # å˜—è©¦å¾ profile æŠ“
        q_company = profile.get("company", "æœªæä¾›")
        q_income = str(profile.get("income", "0"))

        dve_input_data = {
            "æ ¸å¿ƒè­˜åˆ¥è³‡è¨Š": {
                "ç”³è«‹äººå§“å": user_name,
                "èº«åˆ†è­‰å­—è™Ÿ": user_id
            },
            "æœ€æ–°å£è¿°è³‡è¨Š (Query) æ“·å–": {
                "è·æ¥­": q_job,
                "è³‡é‡‘ç”¨é€”": q_purpose,
                "è¯çµ¡é›»è©±": q_phone,
                "æœå‹™å…¬å¸åç¨±": q_company,
                "æœˆè–ª": q_income
            },
            "RAG æª¢ç´¢çš„æ­·å²æ•¸æ“š (Context) æ“·å–": rag_context
        }
        
        input_json_str = json.dumps(dve_input_data, ensure_ascii=False)

        # --- Debug ---
        print("\n" + "="*50)
        print("ğŸ“ DVE æœ€çµ‚çµ„è£çš„ Input JSON:")
        print(json.dumps(dve_input_data, indent=2, ensure_ascii=False))
        print("="*50 + "\n")

        # --- 4. å‘¼å« LLM (Stream Mode) ---
        streamer = TextStreamer(self.llm._tokenizer, skip_prompt=True)
        print(f"ğŸŒŠ Input JSON å·²æ§‹å»ºï¼Œé•·åº¦: {len(input_json_str)} chars")
        print("ğŸŒŠ é–‹å§‹ç”Ÿæˆ (Stream Mode)... è«‹çœ‹ä¸‹æ–¹è¼¸å‡º ğŸ‘‡")

        model = self.llm._base_model
        tokenizer = self.llm._tokenizer
        
        model = PeftModel.from_pretrained(model, DVE_ADAPTER_PATH)
        model.eval()

        prompt = DVE_PROMPT_TEMPLATE.format(DVE_INSTRUCTION, input_json_str)
        inputs = tokenizer(prompt, return_tensors="pt").to(DEVICE)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                streamer=streamer,
                max_new_tokens=512,
                temperature=0.1,
                repetition_penalty=1.2,
                eos_token_id=tokenizer.eos_token_id
            )
        
        # --- 5. è§£æèˆ‡ç­–ç•¥åˆ†æµ ---
        full_text = tokenizer.decode(outputs[0], skip_special_tokens=False) # æ”¹æˆ False ä»¥ä¾¿æˆ‘å€‘åµæ¸¬ç‰¹æ®Šç¬¦è™Ÿ
        
        try:
            # Step A: ç²—ç•¥åˆ‡å‰²
            if "<|end_of_text|>" in full_text: full_text = full_text.split("<|end_of_text|>")[0]
            # åˆ‡å‰²é¬¼æ‰“ç‰†
            # if "<|end_of_text|>" in full_text: full_text = full_text.split("<|end_of_text|>")[0]
            # if "<|begin_of_text|>" in full_text: full_text = full_text.split("<|begin_of_text|>")[1]
            # if "<|begin_of_text|>" in full_text: full_text = full_text.split("<|begin_of_text|>")[0]
            if "### Output:" in full_text: generated_text = full_text.split("### Output:")[1].strip()
            else: generated_text = full_text
            
            # Step B: æ¸…æ´—å·²çŸ¥çš„æ€ªç•° Token
            generated_text = generated_text.replace("PortÃ¡ly", "")

            # Step C: JSON æå– (å„ªå…ˆä½¿ç”¨ Regexï¼Œå®ƒèƒ½è™•ç†å­—ä¸²å…§çš„æ‹¬è™Ÿ)
            # é€™å€‹ Regex å°‹æ‰¾æœ€å¤–å±¤çš„ { ... }ï¼Œre.DOTALL è®“é»è™ŸåŒ¹é…æ›è¡Œç¬¦
            match = re.search(r"(\{.*\})", generated_text, re.DOTALL)
            
            json_str = ""
            if match:
                json_str = match.group(1)
            else:
                # Fallback: å¦‚æœ Regex å¤±æ•—ï¼Œä½¿ç”¨æœ€ç°¡å–®çš„ find/rfind
                # é€™ç¨®æ–¹å¼æ¯”æ‰‹å‹•è¨ˆæ•¸è¿´åœˆæ›´ä¸å®¹æ˜“è¢«å­—ä¸²å…§çš„ç¬¦è™Ÿå¹²æ“¾
                start_idx = generated_text.find("{")
                end_idx = generated_text.rfind("}")
                if start_idx != -1 and end_idx != -1:
                    json_str = generated_text[start_idx : end_idx+1]

            if not json_str:
                raise ValueError("ç„¡æ³•æå– JSON çµæ§‹")

            # Step D: JSON è¼‰å…¥èˆ‡ä¿®å¾©å˜—è©¦
            try:
                report = json.loads(json_str)
            except json.JSONDecodeError:
                # å˜—è©¦å¸¸è¦‹ä¿®å¾©ï¼šè£œé½Šçµå°¾å¼•è™Ÿ (é‡å° 'Expecting , delimiter' éŒ¯èª¤)
                if json_str.count('"') % 2 != 0:
                    json_str = json_str.replace('"}', '"}') # å˜—è©¦ä¿®å¾©
                # æœ€å¾Œå†è©¦ä¸€æ¬¡ï¼Œå¤±æ•—å°±æ‹‹å‡º
                report = json.loads(json_str)

            print(f"\nğŸ” æœ€çµ‚è§£ææˆåŠŸ JSON: {str(report)[:100]}...")
            
            # --- è®€å–çµæœ ---
            # æ³¨æ„ï¼šæ‚¨çš„æ¸¬è©¦è³‡æ–™è¼¸å‡º "MISMATCH_FOUND"ï¼Œä½†ä¹‹å‰çš„ç¨‹å¼ç¢¼åªçœ‹ "HIGH"
            # é€™è£¡æˆ‘å€‘è¦èª¿æ•´é‚è¼¯ï¼Œè®“ MISMATCH_FOUND å°æ‡‰åˆ° HIGH/MEDIUM  é¢¨éšª
            check_status = report.get("æ ¸å¯¦ç‹€æ…‹", "UNKNOWN")
            risk_level = report.get("é¢¨éšªæ¨™è¨˜", "MEDIUM")
            
            # å¼·åˆ¶é‚è¼¯ï¼šå¦‚æœæœ‰ MISMATCH_FOUNDï¼Œé¢¨éšªçµ•å°ä¸å¯èƒ½æ˜¯ LOW
            if check_status == "MISMATCH_FOUND" and risk_level == "LOW":
                 risk_level = "MEDIUM"
            
            # ==========================================
            # ğŸŸ¢ [å„ªåŒ–] è‡ªå‹•å­˜æª”æ©Ÿåˆ¶ (Auto-Write Back)
            # ==========================================
            print(f"ğŸ’¾ æ­£åœ¨å°å­˜æœ¬æ¬¡ç”³è«‹è³‡æ–™è‡³ MongoDB ({user_name})...")
            archive_content = (
                f"ã€éŠ€è¡Œå…§éƒ¨å­˜æª”ã€‘\n"
                f"å­˜æª”æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"å®¢æˆ¶å§“åï¼š{user_name} ({user_id})ã€‚\n"
                f"è·æ¥­ç´€éŒ„ï¼šä»»è·æ–¼ã€Œ{q_company}ã€ï¼Œè·ç¨±ç‚ºã€Œ{q_job}ã€ã€‚\n"
                f"è²¡å‹™ç´€éŒ„ï¼šå£è¿°æœˆè–ª {q_income} å…ƒã€‚\n"
                f"æŸ¥æ ¸çµæœï¼šæœ¬æ¬¡ DVE æŸ¥æ ¸é¢¨éšªç‚º {risk_level}ã€‚"
            )
            
            # Metadata å¿…é ˆå‹•æ…‹å¯«å…¥
            archive_meta = {
                "name": user_name,
                "hist_job": q_job,
                "hist_company": q_company,
                "hist_income": q_income,
                "hist_phone": q_phone,       # <--- ç¾åœ¨æ˜¯å‹•æ…‹çš„äº†
                "hist_purpose": q_purpose,   # <--- ç¾åœ¨æ˜¯å‹•æ…‹çš„äº†
                "default_record": "ç„¡",      # æ–°ç”³è«‹å‡è¨­ç„¡é•ç´„ (æˆ–å¯ä¿ç•™èˆŠç´€éŒ„)
                "inquiry_count": str(int(rag_context.get("ä¿¡ç”¨å ±å‘ŠæŸ¥è©¢æ¬¡æ•¸", "0")) + 1), # æŸ¥è©¢æ¬¡æ•¸+1
                "last_risk_level": risk_level
            }
            
            # 3. å¯«å…¥è³‡æ–™åº«
            rag_engine.add_document(user_id, archive_content, metadata=archive_meta)
            print("âœ… è³‡æ–™å°å­˜å®Œæˆï¼å·²æˆç‚ºæ–°çš„æ­·å²ç´€éŒ„ã€‚")
            # ==========================================
            
            # å›å‚³çµæœ
            if risk_level == "LOW":
                user_res = "è³‡æ–™é©—è­‰ç„¡èª¤ï¼Œæ­£åœ¨ç‚ºæ‚¨é€²è¡Œè©¦ç®—ã€‚"
                next_step = "TRANSFER_TO_FRE"
            elif risk_level == "HIGH":
                user_res = "ç³»çµ±åµæ¸¬åˆ°æ‚¨çš„è³‡æ–™èˆ‡ç´€éŒ„æœ‰å‡ºå…¥ï¼Œè«‹èªªæ˜ç›®å‰ç‹€æ³ã€‚"
                next_step = "FORCE_LDE_CLARIFY"
            else:
                user_res = "è³‡æ–™å·²å—ç†ï¼Œå°‡è½‰ç”±äººå·¥è¦†æ ¸ã€‚"
                next_step = "TRANSFER_TO_FRE"

            return {
                "expert": f"DVE ({risk_level})",
                "response": user_res,
                "dve_raw_report": report,
                "next_step": next_step
            }

        except Exception as e:
            print(f"\nâŒ DVE è§£æå¤±æ•—: {e}")
            return {
                "expert": "DVE (Error)",
                "response": "ç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œã€‚",
                "next_step": "HUMAN_HANDOVER"
            }