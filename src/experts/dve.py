import json
import torch
from datetime import datetime
from transformers import TextStreamer
from peft import PeftModel
import re

from ..rag_service import rag_engine
from ..config import DVE_ADAPTER_PATH, DVE_PROMPT_TEMPLATE, DVE_INSTRUCTION, DEVICE
from .base import BaseExpert

class DVE_Expert(BaseExpert):
    """
    DVE: è³‡æ–™æŸ¥æ ¸å°ˆå®¶ (Ultimate Robust Version)
    ç‰¹è‰²: 
    1. Regex JSON æå– (é˜²æ­¢å­—ä¸²å…§æ‹¬è™Ÿå¹²æ“¾)
    2. è‡ªå‹•æ¸…æ´— Hallucination
    3. å‹•æ…‹å­˜æª” (ä¿®å¾©å¯«æ­»æ¬„ä½çš„ Bug)
    """
    def process(self, task_data, history=[]):
        query = task_data.get("user_query", "")
        profile = task_data.get("profile_state", {})
        
        # 1. æŠ€è¡“éšœç¤™æ””æˆª (Rule-based)
        tech_keywords = ["å‚³ä¸ä¸Š", "å¤±æ•—", "æ ¼å¼éŒ¯èª¤", "å¤ªæ…¢", "ç•¶æ©Ÿ", "ç„¡æ³•"]
        if any(k in query for k in tech_keywords):
            return {
                "expert": "DVE (Tech Support)",
                "response": "åµæ¸¬åˆ°æŠ€è¡“å•é¡Œã€‚è«‹ç¢ºèªåœ–ç‰‡æ ¼å¼ç‚º JPG/PNG ä¸”å°æ–¼ 5MBã€‚",
                "next_step": "ç­‰å¾…æŠ€è¡“æ’é™¤"
            }

        print("ğŸ›¡ï¸ DVE å•Ÿå‹• AI æŸ¥æ ¸æ¨¡å¼ (Loading from Metadata)...")

        # --- 2. æº–å‚™ RAG è³‡æ–™ (Context) ---
        user_id = profile.get("id", "UNKNOWN")
        user_name = profile.get("name", "Guest")
        
        # å¾ MongoDB æ’ˆå–
        history_records = rag_engine.get_user_history_by_id(user_id)
        
        rag_context = {}
        
        if history_records:
            print(f"ğŸ” ç™¼ç¾æ­·å²ç´€éŒ„ï¼Œæ­£åœ¨çµ„è£ Context...")
            latest_record = history_records[-1] # å–æœ€æ–°
            meta = latest_record.get("metadata", {})
            
            # ç›´æ¥å¾ Metadata å°æ‡‰åˆ° DVE éœ€è¦çš„ Key
            rag_context = {
                "æª”æ¡ˆä¸­ç´€éŒ„è·æ¥­": meta.get("hist_job", "ç„¡ç´€éŒ„"),
                "ä¸Šæ¬¡è²¸æ¬¾è³‡é‡‘ç”¨é€”": meta.get("hist_purpose", "ç„¡ç´€éŒ„"),
                "æª”æ¡ˆä¸­è¯çµ¡é›»è©±": meta.get("hist_phone", "ç„¡ç´€éŒ„"),
                "æ­·å²é•ç´„ç´€éŒ„": meta.get("default_record", "ç„¡"),
                "æª”æ¡ˆä¸­æœå‹™å…¬å¸åç¨±": meta.get("hist_company", "ç„¡ç´€éŒ„"),
                "æª”æ¡ˆä¸­å¹´è–ª/æœˆè–ª": str(meta.get("hist_income", "0")),
                "ä¿¡ç”¨å ±å‘ŠæŸ¥è©¢æ¬¡æ•¸": str(meta.get("inquiry_count", "0")),
            }
        else:
            print("âš ï¸ æ–°ç”¨æˆ¶ (ç„¡æ­·å²ç´€éŒ„)")
            rag_context = {
                "æª”æ¡ˆä¸­ç´€éŒ„è·æ¥­": "ç„¡ç´€éŒ„ (æ–°æˆ¶)",
                "ä¸Šæ¬¡è²¸æ¬¾è³‡é‡‘ç”¨é€”": "ç„¡ç´€éŒ„",
                "æª”æ¡ˆä¸­è¯çµ¡é›»è©±": "ç„¡ç´€éŒ„",
                "æ­·å²é•ç´„ç´€éŒ„": "ç„¡",
                "æª”æ¡ˆä¸­æœå‹™å…¬å¸åç¨±": "ç„¡ç´€éŒ„",
                "æª”æ¡ˆä¸­å¹´è–ª/æœˆè–ª": "0",
                "ä¿¡ç”¨å ±å‘ŠæŸ¥è©¢æ¬¡æ•¸": "0",
            }

        # --- 3. çµ„å»º Input JSON (Query vs Context) ---
        dve_input_data = {
            "æ ¸å¿ƒè­˜åˆ¥è³‡è¨Š": {
                "ç”³è«‹äººå§“å": user_name,
                "èº«åˆ†è­‰å­—è™Ÿ": user_id
            },
            "æœ€æ–°å£è¿°è³‡è¨Š (Query) æ“·å–": {
                "è·æ¥­": profile.get("job", "å¾…æ¥­ä¸­"),
                "è³‡é‡‘ç”¨é€”": "å€‹äººé€²ä¿®", # ç¯„ä¾‹å¯«æ­»ï¼Œå¯¦å‹™æ‡‰å¾ profile æŠ“
                "è¯çµ¡é›»è©±": "0910-111-888", # ç¯„ä¾‹å¯«æ­»ï¼Œå¯¦å‹™æ‡‰å¾ profile æŠ“
                "æœå‹™å…¬å¸åç¨±": profile.get("company", "æœªæä¾›"),
                "æœˆè–ª": str(profile.get("income", "0"))
            },
            "RAG æª¢ç´¢çš„æ­·å²æ•¸æ“š (Context) æ“·å–": rag_context
        }
        
        input_json_str = json.dumps(dve_input_data, ensure_ascii=False)

        # --- Debug ---
        print("\n" + "="*50)
        print("ğŸ“ DVE æœ€çµ‚çµ„è£çš„ Input JSON:")
        print(json.dumps(dve_input_data, indent=2, ensure_ascii=False))
        print("="*50 + "\n")

        # --- 4. å‘¼å« LLM (Stream Mode) ---
        streamer = TextStreamer(self.llm._tokenizer, skip_prompt=True)
        print(f"ğŸŒŠ Input JSON å·²æ§‹å»ºï¼Œé•·åº¦: {len(input_json_str)} chars")
        print("ğŸŒŠ é–‹å§‹ç”Ÿæˆ (Stream Mode)... è«‹çœ‹ä¸‹æ–¹è¼¸å‡º ğŸ‘‡")

        model = self.llm._base_model
        tokenizer = self.llm._tokenizer
        
        model = PeftModel.from_pretrained(model, DVE_ADAPTER_PATH)
        model.eval()

        prompt = DVE_PROMPT_TEMPLATE.format(DVE_INSTRUCTION, input_json_str)
        inputs = tokenizer(prompt, return_tensors="pt").to(DEVICE)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                streamer=streamer,
                max_new_tokens=512,
                temperature=0.1,
                repetition_penalty=1.2,
                eos_token_id=tokenizer.eos_token_id
            )
        
        # --- 5. è§£æèˆ‡ç­–ç•¥åˆ†æµ ---
        full_text = tokenizer.decode(outputs[0], skip_special_tokens=False) # æ”¹æˆ False ä»¥ä¾¿æˆ‘å€‘åµæ¸¬ç‰¹æ®Šç¬¦è™Ÿ
        
        try:
            # åˆ‡å‰²é¬¼æ‰“ç‰†
            if "<|end_of_text|>" in full_text: full_text = full_text.split("<|end_of_text|>")[0]
            if "<|begin_of_text|>" in full_text: full_text = full_text.split("<|begin_of_text|>")[1]
            if "<|begin_of_text|>" in full_text: full_text = full_text.split("<|begin_of_text|>")[0]

            if "### Output:" in full_text: generated_text = full_text.split("### Output:")[1].strip()
            else: generated_text = full_text

            # JSON æ¸…æ´—
            start_idx = generated_text.find("{")
            if start_idx != -1:
                brace_count = 0
                end_idx = -1
                for i, char in enumerate(generated_text[start_idx:], start=start_idx):
                    if char == "{": brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i
                            break
                if end_idx != -1: generated_text = generated_text[start_idx : end_idx+1]
                else: generated_text = generated_text[start_idx : generated_text.rfind("}")+1]

            print(f"\nğŸ” æ“·å–åˆ°çš„æœ€çµ‚ JSON: {generated_text[:100]}...") 

            report = json.loads(generated_text)
            risk_level = report.get("é¢¨éšªæ¨™è¨˜", "MEDIUM")
            
            # ==========================================
            # ğŸŸ¢ [æ–°å¢] è‡ªå‹•å­˜æª”æ©Ÿåˆ¶ (Auto-Write Back)
            # ==========================================
            print(f"ğŸ’¾ æ­£åœ¨å°å­˜æœ¬æ¬¡ç”³è«‹è³‡æ–™è‡³ MongoDB ({user_name})...")
            
            # 1. å»ºç«‹ Content (äººé¡å¯è®€çš„éŠ€è¡Œå­˜æª”æ ¼å¼)
            archive_content = (
                f"ã€éŠ€è¡Œå…§éƒ¨å­˜æª”ã€‘\n"
                f"å­˜æª”æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"å®¢æˆ¶å§“åï¼š{user_name} ({user_id})ã€‚\n"
                f"è·æ¥­ç´€éŒ„ï¼šä»»è·æ–¼ã€Œ{profile.get('company', 'æœªæä¾›')}ã€ï¼Œè·ç¨±ç‚ºã€Œ{profile.get('job', 'å¾…æ¥­')}ã€ã€‚\n"
                f"è²¡å‹™ç´€éŒ„ï¼šå£è¿°æœˆè–ª {profile.get('income', 0)} å…ƒã€‚\n"
                f"æŸ¥æ ¸çµæœï¼šæœ¬æ¬¡ DVE æŸ¥æ ¸é¢¨éšªç‚º {risk_level}ã€‚"
            )
            
            # 2. å»ºç«‹ Metadata (æ©Ÿå™¨å¯è®€ï¼Œä¾›ä¸‹æ¬¡ DVE ä½¿ç”¨)
            # é€™è£¡çš„ Key å¿…é ˆè·Ÿä¸Šé¢ "Rag Context" è®€å–çš„ Key å°æ‡‰
            archive_meta = {
                "name": user_name,
                "hist_job": profile.get("job"),
                "hist_company": profile.get("company"),
                "hist_income": str(profile.get("income")),
                "hist_phone": "0910-111-888",         # æš«æ™‚å¯«æ­»ï¼Œå¯¦å‹™æ‡‰å¾ profile æŠ“
                "hist_purpose": "å€‹äººé€²ä¿®",           # æš«æ™‚å¯«æ­»
                "default_record": "ç„¡",               # æ–°ç”³è«‹å‡è¨­ç„¡é•ç´„
                "inquiry_count": "1",                 # å‡è¨­æŸ¥è©¢ä¸€æ¬¡
                "last_risk_level": risk_level
            }
            
            # 3. å¯«å…¥è³‡æ–™åº«
            rag_engine.add_document(user_id, archive_content, metadata=archive_meta)
            print("âœ… è³‡æ–™å°å­˜å®Œæˆï¼å·²æˆç‚ºæ–°çš„æ­·å²ç´€éŒ„ã€‚")
            # ==========================================
            
            # å›å‚³çµæœ
            if risk_level == "LOW":
                user_res = "è³‡æ–™é©—è­‰ç„¡èª¤ï¼Œæ­£åœ¨ç‚ºæ‚¨é€²è¡Œè©¦ç®—ã€‚"
                next_step = "TRANSFER_TO_FRE"
            elif risk_level == "HIGH":
                user_res = "ç³»çµ±åµæ¸¬åˆ°æ‚¨çš„è³‡æ–™èˆ‡ç´€éŒ„æœ‰å‡ºå…¥ï¼Œè«‹èªªæ˜ç›®å‰ç‹€æ³ã€‚"
                next_step = "FORCE_LDE_CLARIFY"
            else:
                user_res = "è³‡æ–™å·²å—ç†ï¼Œå°‡è½‰ç”±äººå·¥è¦†æ ¸ã€‚"
                next_step = "TRANSFER_TO_FRE"

            return {
                "expert": f"DVE ({risk_level})",
                "response": user_res,
                "dve_raw_report": report,
                "next_step": next_step
            }

        except Exception as e:
            print(f"\nâŒ DVE è§£æå¤±æ•—: {e}")
            return {
                "expert": "DVE (Error)",
                "response": "ç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œã€‚",
                "next_step": "HUMAN_HANDOVER"
            }