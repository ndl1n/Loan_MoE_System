import openai
import json
from ..config import OPENAI_API_KEY, OPENAI_MODEL, LDE_ADAPTER_PATH, LDE_SYSTEM_INSTRUCTION
from .base import BaseExpert

client = openai.OpenAI(api_key=OPENAI_API_KEY)

class LDE_Expert(BaseExpert):
    """
    LDE: è²¸æ¬¾å¾µå¯©å°ˆå®¶ (Loan Default Expert)
    Mode A: Local LLM (è«®è©¢)
    Mode B: OpenAI (è³‡æ–™èƒå–)
    """
    def process(self, task_data, history=[]):
        query = task_data.get("user_query", "")
        profile = task_data.get("profile_state", {})
        
        filled_count = sum(1 for v in profile.values() if v)
        keywords = ["å¤šå°‘", "åˆ©ç‡", "ä»€éº¼", "è³‡æ ¼", "å¯ä»¥å—", "è©¦ç®—", "å¥½é", "æ¨è–¦"]
        is_question = any(x in query for x in keywords)
        
        # === Mode A: è«®è©¢æ¨¡å¼ ===
        if filled_count <= 2 and is_question:
            print(f"ğŸ¤– LDE Mode A (Consult): Local LLM")
            ai_response = self.llm.get_expert_response(
                adapter_path=LDE_ADAPTER_PATH,
                instruction=LDE_SYSTEM_INSTRUCTION, 
                user_input=query,
                max_new_tokens=256
            )
            return {
                "expert": "LDE (Consult)",
                "response": ai_response,
                "updated_profile": None,
                "next_step": "ç­‰å¾…ç”³è«‹æ„é¡˜"
            }
            
        # === Mode B: å¼•å°æ¨¡å¼ ===
        else:
            print("ğŸ¤– LDE Mode B (Guide): OpenAI Extract")
            extraction_result = self._openai_extract(query, profile, history)
            
            updated_profile = extraction_result.get("updated_profile", {})
            current_full_profile = profile.copy()
            if updated_profile:
                current_full_profile.update(updated_profile)
                
            required = ["name", "id", "job", "income", "amount"]
            missing = [k for k in required if not current_full_profile.get(k)]
            
            response_text = extraction_result.get("reply_to_user")
            if not response_text:
                response_text = f"æ”¶åˆ°ã€‚é‚„éœ€è¦è«‹å•æ‚¨çš„ï¼š{missing[0]}ï¼Ÿ" if missing else "è³‡æ–™å·²æ”¶é›†å®Œç•¢ã€‚"
            
            return {
                "expert": "LDE (Guide)",
                "response": response_text,
                "updated_profile": updated_profile,
                "next_step": "ç­‰å¾…è£œä»¶" if missing else "è³‡æ–™å®Œæ•´"
            }

    def _openai_extract(self, query, current_profile, history):
        system_prompt = f"""
        ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è²¸æ¬¾ç”³è«‹å¼•å°æ©Ÿå™¨äººã€‚
        1. ç•¶å‰è³‡æ–™ç‹€æ…‹: {json.dumps(current_profile, ensure_ascii=False)}
        2. ç›®æ¨™: å¼•å°å¡«æ»¿ (name, id, job, income, amount)ã€‚
        3. è¼¸å‡º JSON: {{"updated_profile": {{...}}, "reply_to_user": "..."}}
        """
        messages = [{"role": "system", "content": system_prompt}]
        if history: messages.extend(history[-5:])
        messages.append({"role": "user", "content": query})

        try:
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=messages,
                response_format={"type": "json_object"},
                temperature=0.2
            )
            return json.loads(response.choices[0].message.content)
        except Exception:
            return {"updated_profile": {}, "reply_to_user": "ç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"}