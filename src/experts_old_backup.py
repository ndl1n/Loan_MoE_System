import openai
import json
from .config import *
from .llm_utils import LocalLLMManager

# åˆå§‹åŒ– OpenAI
client = openai.OpenAI(api_key=OPENAI_API_KEY)

class BaseExpert:
    def __init__(self):
        self.llm_manager = LocalLLMManager.get_instance()

    def process(self, task_data):
        raise NotImplementedError

    def _call_local_llm(self, adapter_path, system_prompt, user_query):
        """å‘¼å«æœ¬åœ°å¾®èª¿æ¨¡å‹"""
        full_prompt = f"System: {system_prompt}\nUser: {user_query}\nAssistant:"
        return self.llm_manager.get_expert_response(adapter_path, full_prompt)

class LDE_Expert(BaseExpert):
    """
    LDE: è²¸æ¬¾å¾µå¯©å°ˆå®¶ (Loan Default Expert)
    ---------------------------------------------------
    Mode A (Consult): Local LLM (é‡‘èçŸ¥è­˜å•ç­”) - ä½¿ç”¨å¾®èª¿éçš„ Llama-3
    Mode B (Guide):   OpenAI API (è³‡æ–™èƒå–èˆ‡æ­£è¦åŒ–) - è² è²¬å¡«å¯«ç”³è«‹è¡¨
    """

    def process(self, task_data, history=[]):
        query = task_data.get("user_query", "")
        profile = task_data.get("profile_state", {})
        
        # 1. åˆ¤æ–·æ¨¡å¼é‚è¼¯
        # è¨ˆç®—å·²å¡«å¯«çš„æ¬„ä½æ•¸é‡ (æ’é™¤ None æˆ–ç©ºå­—ä¸²)
        filled_count = sum(1 for v in profile.values() if v)
        
        # é—œéµå­—åµæ¸¬ï¼šåˆ¤æ–·ç”¨æˆ¶æ˜¯å¦åœ¨å•å•é¡Œ
        keywords = ["å¤šå°‘", "åˆ©ç‡", "ä»€éº¼", "è³‡æ ¼", "å¯ä»¥å—", "è©¦ç®—", "å¥½é", "æ¨è–¦"]
        is_question = any(x in query for x in keywords)
        
        # === Mode A: è«®è©¢æ¨¡å¼ (ä½¿ç”¨ Local LLM) ===
        # è§¸ç™¼æ¢ä»¶ï¼šè³‡æ–™é‚„æ²’å¡«å¤šå°‘ (filled_count <= 2) ä¸” ç”¨æˆ¶åœ¨å•å•é¡Œ
        if filled_count <= 2 and is_question:
            print(f"ğŸ¤– LDE é€²å…¥ Mode A (Local LLM): å›ç­”é‡‘èå•é¡Œ")
            
            # å‘¼å«æˆ‘å€‘å‰›å‰›ä¿®å¥½çš„ Alpaca æ ¼å¼æ¨è«–å‡½æ•¸
            # LDE_SYSTEM_INSTRUCTION ä¾†è‡ª config.py
            ai_response = self.llm.get_expert_response(
                adapter_path=LDE_ADAPTER_PATH,
                instruction=LDE_SYSTEM_INSTRUCTION, 
                user_input=query,
                max_new_tokens=256
            )
            
            return {
                "expert": "LDE (Consult)",
                "response": ai_response,
                "updated_profile": None, # è«®è©¢æ¨¡å¼é€šå¸¸ä¸æ›´æ–°å€‹è³‡
                "next_step": "ç­‰å¾…ç”³è«‹æ„é¡˜"
            }
            
        # === Mode B: å¼•å°æ¨¡å¼ (ä½¿ç”¨ OpenAI é€²è¡Œè³‡æ–™èƒå–) ===
        # è§¸ç™¼æ¢ä»¶ï¼šç”¨æˆ¶æ²’åœ¨å•å•é¡Œï¼Œæˆ–æ˜¯å·²ç¶“é€²å…¥å¡«è¡¨éšæ®µ
        else:
            print("ğŸ¤– LDE é€²å…¥ Mode B (OpenAI): é€²è¡Œè³‡æ–™èƒå–...")
            
            # å‚³å…¥æ­·å²ç´€éŒ„çµ¦ OpenAI é€²è¡Œ Context åˆ¤è®€
            extraction_result = self._openai_extract(query, profile, history)
            
            # åˆ¤æ–·é‚„ç¼ºå“ªäº›æ¬„ä½
            required_fields = ["name", "id", "job", "income", "amount"]
            updated_profile = extraction_result.get("updated_profile", {})
            
            # åˆä½µæ–°èˆŠè³‡æ–™ä¾†æª¢æŸ¥ç¼ºä»¶
            # æ³¨æ„ï¼šé€™è£¡åªæ˜¯ç‚ºäº†æª¢æŸ¥ç¼ºä»¶ï¼Œå¯¦éš›æ›´æ–°äº¤çµ¦ main/app.py
            current_full_profile = profile.copy()
            if updated_profile:
                current_full_profile.update(updated_profile)
                
            missing = [k for k in required_fields if not current_full_profile.get(k)]
            
            if not missing:
                # è³‡æ–™å…¨é½Š
                response_text = "æ„Ÿè¬æ‚¨ï¼æ‚¨çš„åŸºæœ¬è³‡æ–™å·²æ”¶é›†å®Œç•¢ï¼Œç³»çµ±å°‡ç«‹å³ç‚ºæ‚¨é€²è¡Œé¢¨éšªè©•ä¼°ã€‚"
                next_action = "è³‡æ–™å®Œæ•´ï¼Œè½‰é€ DVE/FRE"
            else:
                # é‚„ç¼ºä»¶ï¼Œä½¿ç”¨ OpenAI ç”Ÿæˆçš„å¼•å°èª (reply_to_user)
                response_text = extraction_result.get("reply_to_user")
                if not response_text:
                    # é˜²å‘†ï¼šå¦‚æœ OpenAI æ²’å›è©±ï¼Œæ‰‹å‹•è£œä¸€å¥
                    response_text = f"æ”¶åˆ°ã€‚ç‚ºäº†è©•ä¼°æ‚¨çš„é¡åº¦ï¼Œé‚„éœ€è¦è«‹å•æ‚¨çš„ï¼š{missing[0]}ï¼Ÿ"
                next_action = "ç­‰å¾…è£œä»¶"

            return {
                "expert": "LDE (Guide)",
                "response": response_text,
                "updated_profile": updated_profile, # å›å‚³çµ¦ Main æ›´æ–° Redis
                "next_step": next_action
            }

    def _openai_extract(self, query, current_profile, history):
        """
        åˆ©ç”¨ OpenAI æ ¹æ“šã€Œæ­·å²å°è©±ã€èˆ‡ã€Œç•¶å‰ç¼ºä»¶ã€æ±ºå®šå›æ‡‰èˆ‡èƒå–
        """
        # å°‡ Redis çš„æ­·å²ç´€éŒ„è½‰ç‚º OpenAI Message æ ¼å¼
        # é€™è£¡å¾ history å–å‡º contentï¼Œå‡è¨­ history æ ¼å¼ç‚º [{"role":..., "content":...}]
        
        system_prompt = f"""
        ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è²¸æ¬¾ç”³è«‹å¼•å°æ©Ÿå™¨äººã€‚
        1. ç•¶å‰è³‡æ–™ç‹€æ…‹ (State): {json.dumps(current_profile, ensure_ascii=False)}
        2. ä½ çš„ç›®æ¨™ï¼šå¼•å°ç”¨æˆ¶å¡«æ»¿æ‰€æœ‰æ¬„ä½ (name, id, job, income, amount)ã€‚
        3. è¦å‰‡ï¼š
           - å¦‚æœç¼ºæ¬„ä½ï¼Œè«‹æ ¹æ“šå°è©±æ­·å²ï¼Œè‡ªç„¶çš„è¿½å•ä¸‹ä¸€å€‹æ¬„ä½ã€‚
           - å¦‚æœç”¨æˆ¶æä¾›äº†è³‡æ–™ï¼Œè«‹èƒå–ä¸¦æ›´æ–° Stateã€‚
           - æ¯æ¬¡åªå•ä¸€å€‹å•é¡Œï¼Œä¸è¦ä¸€æ¬¡å•å¤ªå¤šã€‚
           - è‹¥ç”¨æˆ¶èªªçš„è©±èˆ‡è²¸æ¬¾ç„¡é—œï¼Œè«‹ç¦®è²Œåœ°æ‹‰å›ä¸»é¡Œã€‚
        4. è¼¸å‡ºæ ¼å¼ (JSON):
           {{
             "updated_profile": {{"job": "å·¥ç¨‹å¸«", "income": "100è¬"...(åƒ…åŒ…å«æœ¬æ¬¡æ›´æ–°æ¬„ä½)}},
             "reply_to_user": "çµ¦ç”¨æˆ¶çš„å›æ‡‰æ–‡å­— (ç¹é«”ä¸­æ–‡)"
           }}
        """
        
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ’å…¥æœ€è¿‘ 5 è¼ªå°è©±æ­·å² (Context)
        # éœ€ç¢ºä¿ history æ ¼å¼æ­£ç¢ºï¼Œè‹¥ history å…§æœ‰é dict ç‰©ä»¶éœ€éæ¿¾
        if history:
            messages.extend(history[-5:])
        
        # æ’å…¥ç•¶å‰ç”¨æˆ¶è¼¸å…¥
        messages.append({"role": "user", "content": query})

        try:
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=messages,
                response_format={"type": "json_object"},
                temperature=0.2 # ä½æº«ä»¥ç¢ºä¿ JSON æ ¼å¼ç©©å®š
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"âŒ OpenAI Extract Error: {e}")
            return {"updated_profile": {}, "reply_to_user": "ç³»çµ±ç¹å¿™ï¼Œè«‹å†è¼¸å…¥ä¸€æ¬¡ã€‚"}

class DVE_Expert(BaseExpert):
    """
    DVE: è³‡æ–™æŸ¥æ ¸é©—è­‰å°ˆå®¶ [cite: 90]
    ä»»å‹™ï¼šè™•ç†æŠ€è¡“æ•…éšœã€é«˜é¢¨éšªæ””æˆªã€è§£é‡‹å¯©æ ¸çµæœ
    """
    def process(self, task_data):
        query = task_data.get("user_query", "")
        # ä½¿ç”¨ DVE Adapter ç”Ÿæˆå›æ‡‰
        system_prompt = "ä½ æ˜¯è³‡æ–™å¯©æ ¸å°ˆå“¡ã€‚è‹¥ç”¨æˆ¶é‡åˆ°æŠ€è¡“å•é¡Œï¼Œæä¾›ä¸Šå‚³å»ºè­°ã€‚è‹¥ç‚ºå¯©æ ¸æŸ¥è©¢ï¼Œèªªæ˜ç›®å‰é€²åº¦ã€‚"
        
        # ç°¡å–®åˆ†é¡æ˜¯ç”¨æˆ¶æŠ±æ€¨é‚„æ˜¯ç´”ç²¹æŸ¥æ ¸
        if any(x in query for x in TECH_KEYWORDS):
            prompt_suffix = " (ç”¨æˆ¶é‡åˆ°æŠ€è¡“å›°é›£ï¼Œè«‹å®‰æ’«ä¸¦æä¾›æ›¿ä»£æ–¹æ¡ˆ)"
        else:
            prompt_suffix = " (ç”¨æˆ¶æ­£åœ¨ç­‰å¾…å¯©æ ¸ï¼Œè«‹èªªæ˜éœ€è¦äººå·¥é©—è­‰)"

        ai_response = self._call_local_llm(DVE_ADAPTER_PATH, system_prompt, query + prompt_suffix)
        
        return {
            "expert": "DVE (Verification)",
            "action": "æŸ¥æ ¸èˆ‡æ”¯æ´",
            "response": ai_response,
            "next_step": "Pending Verification"
        }

class FRE_Expert(BaseExpert):
    """
    FRE: è²¡å‹™é¢¨éšªè©•ä¼°å°ˆå®¶ [cite: 96]
    ä»»å‹™ï¼šç”¢å‡ºæœ€çµ‚æ ¸è²¸å ±å‘Š (Green Channel å¿«é€Ÿé€šé)
    """
    def process(self, task_data):
        profile = task_data.get("profile_state", {})
        # æ§‹å»º Prompt è®“æ¨¡å‹ç”Ÿæˆå°ˆæ¥­å ±å‘Š
        input_text = f"ç”³è«‹äººè³‡æ–™ï¼šè·æ¥­ {profile.get('job')}, æ”¶å…¥ {profile.get('income')}, ç”³è«‹é‡‘é¡ {profile.get('amount')}ã€‚"
        system_prompt = "ä½ æ˜¯éŠ€è¡Œçš„é«˜ç´šé¢¨éšªåˆ†æå¸«ã€‚è«‹æ ¹æ“šå®¢æˆ¶è³‡æ–™ï¼Œç”Ÿæˆä¸€ä»½ç°¡çŸ­çš„æ ¸è²¸è©•ä¼°å ±å‘Šï¼ŒåŒ…å«å»ºè­°åˆ©ç‡èˆ‡é¡åº¦ã€‚"
        
        ai_response = self._call_local_llm(FRE_ADAPTER_PATH, system_prompt, input_text)
        
        return {
            "expert": "FRE (Risk Engine)",
            "action": "ç”¢å‡ºè©•ä¼°å ±å‘Š",
            "response": ai_response,
            "next_step": "Disbursement"
        }

# å°ˆå®¶å·¥å» 
def get_expert_handler(expert_name):
    experts = {
        "LDE": LDE_Expert(),
        "DVE": DVE_Expert(),
        "FRE": FRE_Expert()
    }
    return experts.get(expert_name)