import sys
import os
import time
import torch

# æŠŠ src è³‡æ–™å¤¾åŠ å…¥è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.llm_utils import LocalLLMManager
from src.config import LDE_ADAPTER_PATH

def test_llm():
    print("ğŸš€ é–‹å§‹æ¸¬è©¦ï¼šè¼‰å…¥ Local LLM èˆ‡ Adapter...")
    
    # æª¢æŸ¥ VRAM ç‹€æ…‹
    if torch.cuda.is_available():
        vram_total = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"ğŸ“Š åµæ¸¬åˆ° GPU VRAM ç¸½é‡: {vram_total:.2f} GB")
        if vram_total < 6.0:
            print("âš ï¸ è­¦å‘Š: VRAM å°æ–¼ 6GBï¼ŒLlama-3 8B æ¥µå¯èƒ½ç„¡æ³•è¼‰å…¥ (OOM)ã€‚")
            print("   (ä¸ç”¨æ“”å¿ƒï¼Œå…ˆè®“å®ƒè·‘è·‘çœ‹ï¼Œå¤±æ•—äº†æˆ‘å€‘æœ‰å‚™æ¡ˆ)")
    
    start_time = time.time()
    
    try:
        # 1. æ¸¬è©¦è¼‰å…¥ Base Model
        print(f"â³ æ­£åœ¨è¼‰å…¥åŸºåº•æ¨¡å‹ (Base Model)... è«‹è€å¿ƒç­‰å¾…")
        llm = LocalLLMManager.get_instance()
        print(f"âœ… Base Model è¼‰å…¥æˆåŠŸï¼ (è€—æ™‚: {time.time() - start_time:.2f} ç§’)")
        
        # 2. æ¸¬è©¦æ¨è«– (Inference)
        print("â³ æ­£åœ¨å˜—è©¦ç”Ÿæˆå›æ‡‰...")
        # é€™è£¡æ•…æ„ç”¨ä¸€å€‹ä¸éœ€è¦ Adapter çš„ç°¡å–®æ¸¬è©¦ï¼Œå…ˆæ¸¬åº•å±¤èƒ½ä¸èƒ½è·‘
        res = llm._tokenizer.decode(llm._base_model.generate(
            llm._tokenizer.encode("Hello", return_tensors="pt").to("cuda"), 
            max_new_tokens=10
        )[0])
        print(f"âœ… ç°¡å–®æ¨è«–æˆåŠŸ: {res}")

        # 3. æ¸¬è©¦ Adapter (å¦‚æœä¸Šé¢æ²’æ›æ‰çš„è©±)
        print(f"â³ æ­£åœ¨æ›è¼‰ Adapter: {LDE_ADAPTER_PATH}")
        res_expert = llm.get_expert_response(LDE_ADAPTER_PATH, "è«‹å•è²¸æ¬¾åˆ©ç‡å¤šå°‘ï¼Ÿ", max_new_tokens=50)
        
        print("\n=== æ¸¬è©¦çµæœ ===")
        print(f"ğŸ¤– Expert Response: {res_expert}")
            
    except RuntimeError as e:
        if "out of memory" in str(e).lower():
            print("\nâŒ ã€è¨˜æ†¶é«”ä¸è¶³ (OOM)ã€‘")
            print("æ‚¨çš„ MX350 é¡¯å¡è¨˜æ†¶é«”ä¸è¶³ä»¥è¼‰å…¥é€™å€‹æ¨¡å‹ã€‚")
            print("ğŸ’¡ å»ºè­°æ–¹æ¡ˆï¼šæˆ‘å€‘ä¹‹å¾Œå¯ä»¥æ”¹ç”¨ 'CPU æ¨¡å¼' (è¼ƒæ…¢) æˆ– 'ç´” OpenAI æ¨¡å¼'ã€‚")
        else:
            print(f"\nâŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”Ÿç•°å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_llm()